{"cells":[{"cell_type":"markdown","metadata":{"id":"87e8ba66a90f"},"source":["# Sentiment Analysis using Google Cloud"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eda7d4721c1e"},"outputs":[],"source":["! pip3 install --upgrade --quiet wordcloud\n","\n","! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n","                                 fsspec \\\n","                                 gcsfs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oM1iC_MfAts1","executionInfo":{"status":"ok","timestamp":1715628085933,"user_tz":420,"elapsed":2077,"user":{"displayName":"","userId":""}},"outputId":"670264ef-0509-45f7-86ce-5286f02c33b7","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Updated property [core/project].\n"]}],"source":["PROJECT_ID = \"nemo-493b-final\"  # @param {type:\"string\"}\n","\n","# Set the project id\n","! gcloud config set project {PROJECT_ID}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nsN5NJKSu-GU"},"outputs":[],"source":["REGION = \"us-central1\"  # @param {type: \"string\"}"]},{"cell_type":"markdown","metadata":{"id":"b32c908a390c"},"source":["#### UUID\n","\n","If you are in a live tutorial session, you might be using a shared test account or project. To avoid name collisions between users on resources created, you create a uuid for each instance session, and append it onto the name of resources you create in this tutorial."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d598bcdd2f4e"},"outputs":[],"source":["import random\n","import string\n","\n","\n","# Generate a uuid of a specifed length(default=8)\n","def generate_uuid(length: int = 8) -> str:\n","    return \"\".join(random.choices(string.ascii_lowercase + string.digits, k=length))\n","\n","\n","UUID = generate_uuid()"]},{"cell_type":"markdown","metadata":{"id":"sBCra4QMA2wR"},"source":["### Authenticate your Google Cloud account\n","\n","Depending on your Jupyter environment, you may have to manually authenticate. Follow the relevant instructions below.\n","\n","**1. Vertex AI Workbench**\n","* Do nothing as you are already authenticated.\n","\n","**2. Local JupyterLab instance, uncomment and run:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"254614fa0c46","executionInfo":{"status":"ok","timestamp":1715628112446,"user_tz":420,"elapsed":11035,"user":{"displayName":"","userId":""}},"outputId":"b17de4b6-3573-4eb8-bac9-b0e8cb54bb6f","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Go to the following link in your browser, and complete the sign-in prompts:\n","\n","    https://accounts.google.com/o/oauth2/auth?response_type=code&client_id=32555940559.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fsdk.cloud.google.com%2Fauthcode.html&scope=openid+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fuserinfo.email+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcloud-platform+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fappengine.admin+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fsqlservice.login+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fcompute+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Faccounts.reauth&state=1zgQ0abKQwZaC4ZoSCCAasNHB5Z5vo&prompt=consent&token_usage=remote&access_type=offline&code_challenge=5GtduZGIifi2aaET7lBLsBMzkC4QLZ8PAdi-9OIl0V4&code_challenge_method=S256\n","\n","Once finished, enter the verification code provided in your browser: \n","\n","Command killed by keyboard interrupt\n","\n","^C\n"]}],"source":["! gcloud auth login"]},{"cell_type":"markdown","metadata":{"id":"ef21552ccea8"},"source":["**3. Colab, uncomment and run:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"603adbbf0532"},"outputs":[],"source":["from google.colab import auth\n","auth.authenticate_user()"]},{"cell_type":"markdown","metadata":{"id":"zgPO1eR3CYjk"},"source":["### Create a Cloud Storage bucket\n","\n","Create a storage bucket to store intermediate artifacts such as datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MzGDU7TWdts_"},"outputs":[],"source":["BUCKET_URI = f\"gs://finalprojectnemo-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"]},{"cell_type":"markdown","metadata":{"id":"-EcIXiGsCePi"},"source":["**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NIq7R4HZCfIc"},"outputs":[],"source":["! gsutil mb -l {REGION} -p {PROJECT_ID} {BUCKET_URI}"]},{"cell_type":"markdown","metadata":{"id":"543fd0a71f4d"},"source":["### Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5e0383e0444d"},"outputs":[],"source":["import os\n","from typing import List, Optional, Union\n","\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from google.cloud import aiplatform, storage\n","from wordcloud import STOPWORDS, WordCloud"]},{"cell_type":"markdown","metadata":{"id":"5563f402e958"},"source":["## Load the data\n","<a name=\"section-5\"></a>\n","\n","Load the phrases and scores of the dataset from the Cloud Storage sources."]},{"cell_type":"code","source":["import pandas as pd\n","from nltk.sentiment import SentimentIntensityAnalyzer\n","\n","# Install NLTK and download VADER lexicon\n","!pip install nltk\n","import nltk\n","nltk.download('vader_lexicon')\n","\n","# Read CSV file from Google Cloud Storage\n","df = pd.read_csv(\"gs://finalprojectnemo/filtered_data.csv\")\n","\n","# Initialize the SentimentIntensityAnalyzer\n","sid = SentimentIntensityAnalyzer()\n","\n","# Function to get sentiment\n","def get_sentiment(text):\n","    sentiment = sid.polarity_scores(text)\n","    if sentiment['compound'] >= 0.05:\n","        return 'positive'\n","    elif sentiment['compound'] <= -0.05:\n","        return 'negative'\n","    else:\n","        return 'neutral'\n","\n","# Apply sentiment analysis to the DataFrame\n","df['sentiment'] = df['text'].apply(get_sentiment)\n","\n","# Calculate sentiment percentages\n","sentiment_counts = df['sentiment'].value_counts()\n","sentiment_percentages = sentiment_counts / len(df) * 100\n","\n","# Show sentiment percentages\n","print(\"Sentiment Percentages:\")\n","print(sentiment_percentages)\n","\n","# Generate confusion matrix (assuming you have a 'true_sentiment' column)\n","conf_matrix = pd.crosstab(df['target'], df['sentiment'])\n","\n","# Display confusion matrix\n","print(\"\\nConfusion Matrix:\")\n","print(conf_matrix)\n"],"metadata":{"id":"kIYGb7zPaQZE","executionInfo":{"status":"ok","timestamp":1715628433449,"user_tz":420,"elapsed":10468,"user":{"displayName":"","userId":""}},"outputId":"cc7d4837-0b1d-48af-b2d7-19957d43e570","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Sentiment Percentages:\n","sentiment\n","positive    51.329442\n","neutral     26.588846\n","negative    22.081712\n","Name: count, dtype: float64\n","\n","Confusion Matrix:\n","sentiment  negative  neutral  positive\n","target                                \n","0               524      323       397\n","4               157      497      1186\n"]}]},{"cell_type":"markdown","source":["**Based on the provided sentiment percentages:**\n","\n","- Approximately 51.33% of the sentiments were classified as positive.\n","- Around 26.59% of the sentiments were classified as neutral.\n","- Roughly 22.08% of the sentiments were classified as negative.\n","\n","These percentages indicate the distribution of sentiment classifications in your dataset. Positive sentiments appear to be the most common, followed by neutral sentiments, with negative sentiments being the least common among the data."],"metadata":{"id":"OvRcjAHRb4rR"}},{"cell_type":"markdown","source":["**Based on the provided confusion matrix:**\n","\n","- For the target class 0:\n","  - 524 instances were classified as negative sentiment.\n","  - 323 instances were classified as neutral sentiment.\n","  - 397 instances were classified as positive sentiment.\n","\n","- For the target class 4:\n","  - 157 instances were classified as negative sentiment.\n","  - 497 instances were classified as neutral sentiment.\n","  - 1186 instances were classified as positive sentiment.\n","\n","This confusion matrix helps in understanding how well the sentiment analysis model performed for each sentiment class (negative, neutral, positive) across different target classes (0 and 4, assuming these are the target classes). It shows the number of instances classified correctly and incorrectly into each sentiment category."],"metadata":{"id":"doy6X-57bxqv"}}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/workbench/sentiment_analysis/Sentiment_Analysis.ipynb","timestamp":1715628457925}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}